# -*- coding: utf-8 -*-
"""
äºŒçº§å…¬å¸è¯¦æƒ…æ•°æ®é‡‡é›†è„šæœ¬ï¼ˆæœ€ç»ˆç‰ˆ + ç©ºIDè·³è¿‡å¢å¼ºï¼‰
åŠŸèƒ½ï¼š
  - ä»æ•°æ®åº“è¯»å–å…¬å¸ ID åˆ—è¡¨
  - è°ƒç”¨ API è·å–è¯¦æƒ…
  - å°†æ‰€æœ‰å¤æ‚å­—æ®µï¼ˆlist/dictï¼‰è½¬ä¸º JSON å­—ç¬¦ä¸²åå­˜å…¥ MongoDB
  - æ–­ç‚¹ç»­ä¼  + æ—¥å¿—è®°å½•
  - æ‰€æœ‰å­—æ®µåœ¨æ•°æ®åº“ä¸­å‡ä¸ºå¯è¯»å­—ç¬¦ä¸²ï¼Œä¾¿äºæŸ¥çœ‹å’Œå¯¼å‡º
  - è‡ªåŠ¨è·³è¿‡ id ä¸ºç©ºçš„è®°å½•ï¼Œå¹¶è®°å½•åˆ° invalid_company_records.log
"""

import time
import logging
import os
import json
import requests

# è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥
from è·å–ä»¤ç‰Œ import ä»¤ç‰Œ
from è¯»å–æ•°æ®åº“ import count_companies, iter_companies  # å‡è®¾è¿”å›ç”Ÿæˆå™¨
from database.mongodb import db_manager                  # MongoDB ç®¡ç†å™¨
from config.settings import config                      # é…ç½®æ–‡ä»¶

# ==================== é…ç½®åŒº ====================

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("detail_crawler.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)

# æ–‡ä»¶è·¯å¾„
CHECKPOINT_FILE = "äºŒçº§æ•°æ®.txt"
INVALID_RECORDS_LOG = "invalid_company_records.log"

# MongoDB ç›®æ ‡é›†åˆå
DETAIL_COLLECTION = getattr(config.mongodb, 'collection_detail', 'company_details')

# ====== å…¨å±€ç¼“å­˜ token ======
_cached_token = None

def refresh_token():
    global _cached_token
    logging.info("ğŸ”„ æ­£åœ¨åˆ·æ–°è®¿é—®ä»¤ç‰Œ...")
    _cached_token = ä»¤ç‰Œ()
    return _cached_token

def get_headers():
    global _cached_token
    if _cached_token is None:
        refresh_token()
    return {
        'authorization': f'Bearer {_cached_token}',
        'accept': 'application/json',
        'content-type': 'application/json;charset=UTF-8',
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
                      '(KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36 Edg/142.0.0.0',
        'origin': 'https://yunfu-open.jingxiansuo.com',
        'referer': 'https://yunfu-open.jingxiansuo.com/'
    }

# ==================== æ ¸å¿ƒï¼šå°†å¤æ‚å­—æ®µè½¬ä¸º JSON å­—ç¬¦ä¸² ====================

def normalize_complex_fields(data: dict) -> dict:
    """
    å°†æŒ‡å®šçš„ list / dict ç±»å‹å­—æ®µè½¬æ¢ä¸ºæ ¼å¼åŒ–çš„ JSON å­—ç¬¦ä¸²ï¼Œ
    ç¡®ä¿åœ¨ MongoDB ä¸­ä»¥çº¯æ–‡æœ¬å½¢å¼å­˜å‚¨ï¼Œä¾¿äºæŸ¥çœ‹ã€‚
    """
    target_fields = [
        'companyTags',
        'historyNames',
        'products',
        'socialSecurities',
        'businessScope',
        'websiteStates',
        'judiIInformNum',
        'kpNum',
        'licenseNum',
        'honorNum',
        'standardsNum',
        'interlinkMobileNum',
        'interlinkFixedLineNum',
        'interlinkEmailNum',
        'interlinkQqNum',
        'interlinkWechatNum',
        'interlinkFaxNum',
        'interlinkOtherContactNum',
        'interlinkKpNum',
        'linkinNum',
        'maimaiNum',
        'certificatesNum',
        'curInvestmentNum',
        'investmentNum',
        'hisInvestmentNum',
        'ecommerceNum'
    ]

    result = data.copy()
    for field in target_fields:
        if field in result and isinstance(result[field], (dict, list)):
            try:
                result[field] = json.dumps(result[field], ensure_ascii=False, indent=2)
            except Exception as e:
                logging.warning(f"âš ï¸ å­—æ®µ '{field}' åºåˆ—åŒ–å¤±è´¥ï¼Œæ”¹ç”¨ str(): {e}")
                result[field] = str(result[field])
    return result

# ==================== å·¥å…·å‡½æ•° ====================

def load_processed_ids() -> set:
    """åŠ è½½å·²å¤„ç†çš„ company_id é›†åˆï¼ˆç”¨äºè·³è¿‡ï¼‰"""
    if not os.path.exists(CHECKPOINT_FILE):
        return set()
    try:
        with open(CHECKPOINT_FILE, "r", encoding="utf-8") as f:
            return {line.strip() for line in f if line.strip()}
    except Exception as e:
        logging.error(f"âš ï¸ è¯»å–æ–­ç‚¹æ–‡ä»¶å¤±è´¥: {e}")
        return set()

def record_success(company_id: str):
    """è¿½åŠ å†™å…¥æˆåŠŸå¤„ç†çš„ ID åˆ°æ–­ç‚¹æ–‡ä»¶"""
    try:
        with open(CHECKPOINT_FILE, "a", encoding="utf-8") as f:
            f.write(f"{company_id}\n")
    except Exception as e:
        logging.error(f"âš ï¸ è®°å½•æˆåŠŸ ID å¤±è´¥: {e}")

def save_to_mongo(detail_data: dict) -> bool:
    """å°†å•æ¡å…¬å¸è¯¦æƒ…å†™å…¥ MongoDBï¼ˆå…ˆæ ‡å‡†åŒ–å¤æ‚å­—æ®µï¼‰"""
    if not detail_data or not isinstance(detail_data, dict):
        return False
    try:
        normalized = normalize_complex_fields(detail_data)
        normalized["fetched_at"] = time.strftime("%Y-%m-%d %H:%M:%S")
        ok = db_manager.insert_one(data=normalized, collection_name=DETAIL_COLLECTION)
        return ok
    except Exception as e:
        logging.exception(f"MongoDB å†™å…¥å¼‚å¸¸: {e}")
        return False

# ==================== ä¸»é€»è¾‘ ====================

def run():
    global _cached_token
    total = count_companies()
    processed_ids = load_processed_ids()
    logging.info(f"ğŸ“Š å…± {total} æ¡å…¬å¸æ•°æ®ï¼Œå·²å¤„ç† {len(processed_ids)} æ¡ï¼Œå¼€å§‹è¯·æ±‚...")

    refresh_token()

    for idx, com in enumerate(iter_companies(batch_size=1000), start=1):
        company_id = com.get('id')
        # æ£€æŸ¥ ID æ˜¯å¦æœ‰æ•ˆ
        if not company_id:
            # æ„é€ æ— æ•ˆè®°å½•æ—¥å¿—
            invalid_record = {
                "index": idx,
                "raw_data": com,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
            try:
                with open(INVALID_RECORDS_LOG, "a", encoding="utf-8") as f:
                    f.write(json.dumps(invalid_record, ensure_ascii=False) + "\n")
            except Exception as e:
                logging.error(f"å†™å…¥æ— æ•ˆè®°å½•æ—¥å¿—å¤±è´¥: {e}")

            logging.warning(f"[{idx}] âš ï¸ è·³è¿‡ç©ºæˆ–æ— æ•ˆ ID çš„è®°å½•: {com}")
            continue  # è·³è¿‡æœ¬æ¬¡å¾ªç¯

        company_id_str = str(company_id)
        if company_id_str in processed_ids:
            logging.info(f"[{idx}] âœ… å·²å¤„ç†ï¼Œè·³è¿‡: {company_id_str}")
            continue

        url = (
            f"https://baize-api-yunfu.jingxiansuo.com/DataService/api/v2/company/detail/"
            f"{company_id_str}?clickPath=advanced-search"
        )

        success = False
        max_retries = 3

        for attempt in range(max_retries):
            try:
                headers = get_headers()
                response = requests.get(url, headers=headers, timeout=15)  # è¶…æ—¶ç•¥å¾®æ”¾å®½

                if response.status_code == 200:
                    try:
                        resp_json = response.json()
                        if resp_json.get("status") != 200 or not resp_json.get("success"):
                            message = resp_json.get("message", "æœªçŸ¥é”™è¯¯")
                            logging.warning(f"[{idx}] API ä¸šåŠ¡é”™è¯¯ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰: {message}")
                            refresh_token()
                            if attempt < max_retries - 1:
                                time.sleep(1)
                            continue

                        detail = resp_json.get("data")
                        if not detail:
                            logging.warning(f"[{idx}] æ—  data å­—æ®µï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰: {url}")
                            refresh_token()
                            if attempt < max_retries - 1:
                                time.sleep(1)
                            continue

                        if save_to_mongo(detail):
                            logging.info(f"[{idx}] ğŸ’¾ æˆåŠŸä¿å­˜è¯¦æƒ…: {company_id_str}")
                            success = True
                            break
                        else:
                            logging.error(f"[{idx}] âŒ MongoDB å†™å…¥å¤±è´¥ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰")
                            refresh_token()
                            if attempt < max_retries - 1:
                                time.sleep(1)
                            continue

                    except json.JSONDecodeError:
                        logging.error(
                            f"[{idx}] âŒ JSON è§£æå¤±è´¥ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰: {response.text[:300]}..."
                        )
                        refresh_token()
                        if attempt < max_retries - 1:
                            time.sleep(1)
                        continue

                else:
                    # æ£€æŸ¥æ˜¯å¦è¿”å› HTMLï¼ˆå¦‚ Token å¤±æ•ˆè·³è½¬ç™»å½•é¡µï¼‰
                    content_type = response.headers.get('content-type', '')
                    if 'text/html' in content_type or 'ç¼ºå°‘ä»¤ç‰Œ' in response.text:
                        logging.warning(f"[{idx}] æ£€æµ‹åˆ°é‰´æƒå¤±è´¥é¡µé¢ï¼Œå¼ºåˆ¶åˆ·æ–° Token")
                        refresh_token()
                        if attempt < max_retries - 1:
                            time.sleep(2)
                        continue

                    logging.warning(f"[{idx}] ğŸ“¡ HTTP {response.status_code}ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰")
                    refresh_token()
                    if attempt < max_retries - 1:
                        time.sleep(1)
                    continue

            except requests.RequestException as e:
                logging.warning(f"[{idx}] âš ï¸ ç½‘ç»œå¼‚å¸¸ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰: {e}")
                refresh_token()
                if attempt < max_retries - 1:
                    time.sleep(1)
                continue

        if success:

            record_success(company_id_str)
        else:
            logging.error(f"[{idx}] âŒ æ‰€æœ‰ {max_retries} æ¬¡å°è¯•å‡å¤±è´¥ï¼Œè·³è¿‡å…¬å¸: {company_id_str}")

        time.sleep(1)  # æ§åˆ¶è¯·æ±‚é¢‘ç‡

    logging.info("âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")

# ==================== å¯åŠ¨å…¥å£ ====================
if __name__ == "__main__":
    try:
        run()
    except KeyboardInterrupt:
        logging.info("ğŸ›‘ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        logging.exception(f"ğŸ’¥ ç¨‹åºå´©æºƒ: {e}")