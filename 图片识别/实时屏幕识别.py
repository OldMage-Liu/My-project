import cv2
import numpy as np
import mss
from ultralytics import YOLO
import signal

# ========== é…ç½® ==========
MODEL_PATH = "yolo11x.pt"  # æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹è·¯å¾„
OUTPUT_VIDEO = "screen1_to_screen2_output.mp4"

# å…¨å±€æ§åˆ¶
running = True


def signal_handler(sig, frame):
    global running
    print("\næ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
    running = False


signal.signal(signal.SIGINT, signal_handler)

# ========== åŠ è½½æ¨¡å‹ ==========
print("æ­£åœ¨åŠ è½½ YOLO æ¨¡å‹...")
model = YOLO(MODEL_PATH)

with mss.mss() as sct:
    monitors = sct.monitors  # [0]=è™šæ‹Ÿå…¨å±, [1]=ä¸»å±, [2]=å‰¯å±...

    if len(monitors) < 2:
        raise RuntimeError("æœªæ£€æµ‹åˆ°è‡³å°‘ä¸€å—å±å¹•ï¼")

    input_monitor = monitors[2]  # ğŸ‘ˆ è¯†åˆ«ç¬¬ä¸€å—å±å¹•ï¼ˆä¸»å±ï¼‰

    if len(monitors) < 3:
        print("âš ï¸ æœªæ£€æµ‹åˆ°ç¬¬äºŒå—å±å¹•ï¼Œå°†åœ¨ä¸»å±æ˜¾ç¤ºç»“æœã€‚")
        output_monitor = monitors[2]
    else:
        output_monitor = monitors[1]  # ğŸ‘ˆ æ˜¾ç¤ºåˆ°ç¬¬äºŒå—å±å¹•

    # è·å–è¾“å…¥å¸§å°ºå¯¸ï¼ˆç”¨äº VideoWriterï¼‰
    temp_img = np.array(sct.grab(input_monitor))
    temp_img = cv2.cvtColor(temp_img, cv2.COLOR_BGRA2BGR)
    h, w = temp_img.shape[:2]

    # åˆå§‹åŒ–è§†é¢‘å†™å…¥å™¨
    out = cv2.VideoWriter(
        OUTPUT_VIDEO,
        cv2.VideoWriter_fourcc(*'mp4v'),
        20.0,
        (w, h)
    )

    # åˆ›å»ºæ˜¾ç¤ºçª—å£å¹¶ç§»åˆ°ç¬¬äºŒå±
    win_name = "YOLO: Screen 1 â†’ Screen 2"
    cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(win_name, w, h)  # å¯é€‰ï¼šä¿æŒåŸå§‹æ¯”ä¾‹
    cv2.moveWindow(win_name, output_monitor["left"], output_monitor["top"])

    print(f"âœ… æ­£åœ¨è¯†åˆ«ç¬¬ä¸€å—å±å¹• ({w}x{h})")
    print(f"ğŸ–¥ï¸  ç»“æœå°†æ˜¾ç¤ºåœ¨ç¬¬äºŒå—å±å¹•ï¼ˆå·¦ä¸Šè§’åæ ‡: {output_monitor['left']}, {output_monitor['top']}ï¼‰")
    print(f"ğŸ“¹ è§†é¢‘å°†ä¿å­˜è‡³: {OUTPUT_VIDEO}")
    print("æŒ‰ 'q' é”® æˆ– Ctrl+C é€€å‡ºç¨‹åº")

    frame_count = 0
    try:
        while running:
            # 1. æˆªå–ç¬¬ä¸€å—å±å¹•
            screenshot = sct.grab(input_monitor)
            img = np.array(screenshot)
            img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)

            # 2. YOLO æ¨ç†
            results = model(img, conf=0.5)
            annotated_frame = results[0].plot()

            # 3. ä¿å­˜è§†é¢‘
            out.write(annotated_frame)

            # 4. æ˜¾ç¤ºåˆ°ç¬¬äºŒå—å±å¹•
            cv2.imshow(win_name, annotated_frame)
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break

            frame_count += 1
            if frame_count % 60 == 0:
                print(f"å·²å¤„ç† {frame_count} å¸§...")

    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")

    finally:
        # æ¸…ç†èµ„æº
        out.release()
        cv2.destroyAllWindows()
        print(f"\nâœ… ç¨‹åºç»“æŸï¼Œè§†é¢‘å·²ä¿å­˜è‡³: {OUTPUT_VIDEO}")


